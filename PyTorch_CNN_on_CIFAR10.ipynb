{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNbO8HYxMaIaLSMbMGvgl8T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IshaanKetchup/ASLtoEnglish/blob/main/PyTorch_CNN_on_CIFAR10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "18MNLlJPdgZC",
        "outputId": "743a06af-395a-4829-adfd-c9279517c1ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the Dataset\n"
      ],
      "metadata": {
        "id": "hE1IiPpyrdiM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doArih2GmgCg",
        "outputId": "5438121a-0e01-4556-ccd1-9e8b49efe9ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading in relevant libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Defining relevant variables for the ML task\n",
        "batch_size = 64\n",
        "num_classes = 10\n",
        "learning_rate = 0.001\n",
        "num_epochs = 20\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCQHl3JOdkuq",
        "outputId": "353f1219-1092-4797-c81c-f36546ac0594"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the inbuilt CIFAR10 dataset from torchvision (this is how the tutorial made me do it, so I stuck to it)"
      ],
      "metadata": {
        "id": "_59i0UJmiysy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Used to reformat images for modelling,\n",
        "# and save variable all_transforms for later use\n",
        "all_transforms = transforms.Compose(\n",
        "    [transforms.Resize((32,32)),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize(mean=[0.4914,0.4822,0.4465],\n",
        "                          std = [0.2023, 0.1994, 0.2010])\n",
        "     ]\n",
        ")\n",
        "\n",
        "# Create training dataset\n",
        "train_dataset = torchvision.datasets.CIFAR10(\n",
        "    root = './data',\n",
        "    train=True,\n",
        "    transform = all_transforms,\n",
        "    download = True\n",
        ")\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(\n",
        "    root = './data',\n",
        "    train=False,\n",
        "    transform = all_transforms,\n",
        "    download = True\n",
        ")\n",
        "\n",
        "# Loader objects to facilitate processing\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset = train_dataset,\n",
        "    batch_size = batch_size,\n",
        "    shuffle = True\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    dataset = test_dataset,\n",
        "    batch_size = batch_size,\n",
        "    shuffle = True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5F1StvmmevMm",
        "outputId": "f3a6518d-a82a-4f41-edcf-6de0831c478a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Defining the CNN\n",
        "*   Class that extends the nn.Module class (PyTorch). Needed as it provides useful methods.\n",
        "*   Define layers in NN. Done in the __init__ method, where layers are named and assigned appropriate layer that we want\n",
        "*   Forward method: to define order in which input data passes through layers\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "keFXeLSpiGoZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNeuralNet(nn.Module):\n",
        "  # Determine what layers and their order in CNN object\n",
        "  def __init__(self, num_classes):\n",
        "    super(ConvNeuralNet, self).__init__()\n",
        "    self.conv_layer1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3)\n",
        "    self.conv_layer2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3)\n",
        "    self.max_pool1 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "\n",
        "    self.conv_layer3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
        "    self.conv_layer4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3)\n",
        "    self.max_pool2 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "\n",
        "    self.fc1 = nn.Linear(1600, 128)\n",
        "    self.relu1 = nn.ReLU()\n",
        "    self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "  def forward(self,x):\n",
        "    out = self.conv_layer1(x)\n",
        "    out = self.conv_layer2(out)\n",
        "    out = self.max_pool1(out)\n",
        "\n",
        "    out = self.conv_layer3(out)\n",
        "    out = self.conv_layer4(out)\n",
        "    out = self.max_pool2(out)\n",
        "\n",
        "    out = out.reshape(out.size(0), -1)\n",
        "    out = self.fc1(out)\n",
        "    out = self.relu1(out)\n",
        "    out = self.fc2(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "t3FF8d1yfsww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Setting up hyperparameters\n",
        "Choose cross-entropy as our loss function, and SGD (Stochastic Gradient Descent) as our optimizer\n",
        "Also define a total_step to make iteration through various batches easier"
      ],
      "metadata": {
        "id": "BwkScOx_jGwE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = ConvNeuralNet(num_classes)\n",
        "\n",
        "# Set Loss function with criterion\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.005, momentum = 0.9)\n",
        "\n",
        "total_step = len(train_loader)\n",
        "\n"
      ],
      "metadata": {
        "id": "52RWKGpqivmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training the model\n",
        "\n",
        "\n",
        "1.   Start by iterating through epochs and then batches\n",
        "2.   Convert images and labels according to device configured (GPU/CPU)\n",
        "3. Forward pass: make predictions using our model and calculate loss based on those predictions and actual labels\n",
        "4. Backward pass: update our weights to improve model\n",
        "5. Set Gradients to 0 before every update using `optimizer.zero_grad()`\n",
        "6. Calculate new gradients using `loss.backward()`\n",
        "7. Update weights using `optimizer.step()`\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZK7ign5HktU5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "  model = model.to(torch.device('cuda'))\n",
        "  # Load in the data in batches using tran_loader\n",
        "  for i, (images,labels) in enumerate(train_loader):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # Backward and optimize\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Id6TzOGkrWL",
        "outputId": "3414b450-abc8-446b-f194-e64bb527427b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20], Loss: 0.3151\n",
            "Epoch [2/20], Loss: 0.1227\n",
            "Epoch [3/20], Loss: 0.1259\n",
            "Epoch [4/20], Loss: 0.7392\n",
            "Epoch [5/20], Loss: 0.3301\n",
            "Epoch [6/20], Loss: 0.5891\n",
            "Epoch [7/20], Loss: 0.5990\n",
            "Epoch [8/20], Loss: 0.5488\n",
            "Epoch [9/20], Loss: 0.6056\n",
            "Epoch [10/20], Loss: 0.7046\n",
            "Epoch [11/20], Loss: 0.5006\n",
            "Epoch [12/20], Loss: 0.3136\n",
            "Epoch [13/20], Loss: 0.2654\n",
            "Epoch [14/20], Loss: 0.3677\n",
            "Epoch [15/20], Loss: 0.2788\n",
            "Epoch [16/20], Loss: 0.3517\n",
            "Epoch [17/20], Loss: 0.2839\n",
            "Epoch [18/20], Loss: 0.2991\n",
            "Epoch [19/20], Loss: 0.0596\n",
            "Epoch [20/20], Loss: 0.1721\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing the Model\n",
        "`torch.no_grad()` as there is no need to calculate any gradients. Then predict each batch using our model and calculate how many it predicts correctly\n"
      ],
      "metadata": {
        "id": "40XQkK9mqhxC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the network on the {} train images: {} %'.format(50000, 100 * correct / total))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-W3ynYqRmCdW",
        "outputId": "1fca8925-ca5e-479b-c37d-c51232dac22d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 50000 train images: 94.43 %\n"
          ]
        }
      ]
    }
  ]
}